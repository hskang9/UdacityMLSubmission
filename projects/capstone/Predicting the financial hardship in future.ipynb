{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as pl\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('processed_data/processed_train_data.csv')\n",
    "test = pd.read_csv('processed_data/processed_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train[[\"NumberOfTime30-59DaysPastDueNotWorse\", \"NumberOfTimes90DaysLate\", \"age\", \"NumberOfTime60-89DaysPastDueNotWorse\", \"NumberOfDependents\"]].as_matrix()\n",
    "X_test = test[[\"NumberOfTime30-59DaysPastDueNotWorse\", \"NumberOfTimes90DaysLate\", \"age\", \"NumberOfTime60-89DaysPastDueNotWorse\", \"NumberOfDependents\"]].as_matrix()\n",
    "y_train = train[\"SeriousDlqin2yrs\"].as_matrix()\n",
    "y_test = test[\"SeriousDlqin2yrs\"].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import dependancies# Import dependancies# Import dependancies# Import dependancies# Import dependancies# Import dependancies\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as pl\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "\n",
    "train = pd.read_csv('processed_data/processed_train_data.csv')\n",
    "test = pd.read_csv('processed_data/processed_test_data.csv')\n",
    "\n",
    "X_train = train[[\"NumberOfTime30-59DaysPastDueNotWorse\", \"NumberOfTimes90DaysLate\", \"age\", \"NumberOfTime60-89DaysPastDueNotWorse\", \"NumberOfDependents\"]].as_matrix()\n",
    "X_test = test[[\"NumberOfTime30-59DaysPastDueNotWorse\", \"NumberOfTimes90DaysLate\", \"age\", \"NumberOfTime60-89DaysPastDueNotWorse\", \"NumberOfDependents\"]].as_matrix()\n",
    "y_train = train[\"SeriousDlqin2yrs\"].as_matrix()\n",
    "y_test = test[\"SeriousDlqin2yrs\"].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test): \n",
    "    '''\n",
    "    inputs:\n",
    "       - learner: the learning algorithm to be trained and predicted on\n",
    "       - sample_size: the size of samples (number) to be drawn from training set\n",
    "       - X_train: features training set\n",
    "       - y_train: income training set\n",
    "       - X_test: features testing set\n",
    "       - y_test: income testing set\n",
    "    '''\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Fit the learner to the training data using slicing with 'sample_size' using .fit(training_features[:], training_labels[:])\n",
    "    training_features = X_train[:sample_size]\n",
    "    training_labels = y_train[:sample_size]\n",
    "    start = time() # Get start time\n",
    "    learner = learner.fit(training_features, training_labels)\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # Calculate the training time\n",
    "    results['train_time'] = end - start\n",
    "    \n",
    "    # Get the predictions on the test set(X_test),\n",
    "    #       then get predictions on the first 300 training samples(X_train) using .predict()\n",
    "    start = time() # Get start time\n",
    "    predictions_test = learner.predict(X_test)\n",
    "    predictions_train = learner.predict(X_train[:300])\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    \n",
    "    # Calculate the total prediction time\n",
    "    results['pred_time'] = end - start\n",
    "            \n",
    "    # Compute F1-score on the the first 300 training samples using f1_score()\n",
    "    results['f_train'] = f1_score(y_train[:300], predictions_train)\n",
    "        \n",
    "    # Compute F1-score on the test set which is y_test\n",
    "    results['f_test'] = f1_score(y_test, predictions_test)\n",
    "    \n",
    "    # Compute AUROC-score on the test set which is y_test\n",
    "    results['auroc_train'] = roc_auc_score(y_train[:300], predictions_train)\n",
    "    \n",
    "    # Compute AUROC-score on the test set which is y_test\n",
    "    results['auroc_test'] = roc_auc_score(y_test, predictions_test)\n",
    "    \n",
    "    # Success\n",
    "    print \"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size)\n",
    "        \n",
    "    # Return the results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression trained on 902 samples.\n",
      "LogisticRegression trained on 9020 samples.\n",
      "LogisticRegression trained on 90201 samples.\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42, class_weight='balanced', solver='liblinear')\n",
    "\n",
    "\n",
    "samples_100 = len(y_train)\n",
    "samples_10 = len(y_train)/10\n",
    "samples_1 = len(y_train)/100\n",
    "\n",
    "\n",
    "# Collect results on the learners\n",
    "results = {}\n",
    "clf_name = clf.solver\n",
    "results[clf_name] = {}\n",
    "for i, samples in enumerate([samples_1, samples_10, samples_100]):\n",
    "    results[clf_name][i] = \\\n",
    "    train_predict(clf, samples, X_train, y_train, X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Kaggle test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=1, stop=101504, step=1)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('data/cs-test.csv').drop(\"SeriousDlqin2yrs\", axis=1).fillna(0)\n",
    "Id = test.index + 1\n",
    "Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,  43.,   0.,   0.],\n",
       "       [  0.,   0.,  57.,   0.,   2.],\n",
       "       [  0.,   0.,  59.,   0.,   2.],\n",
       "       ..., \n",
       "       [  0.,   0.,  70.,   0.,   0.],\n",
       "       [  0.,   0.,  56.,   1.,   3.],\n",
       "       [  0.,   0.,  29.,   0.,   0.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test[[\"NumberOfTime30-59DaysPastDueNotWorse\", \"NumberOfTimes90DaysLate\", \"age\", \"NumberOfTime60-89DaysPastDueNotWorse\", \"NumberOfDependents\"]].as_matrix()\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(clf.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame({\"Id\": pd.Series(Id),\"Probability\": predictions[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "![Result]()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
